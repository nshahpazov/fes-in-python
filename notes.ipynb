{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Decision Tree Algorithm\n",
    "\n",
    "\n",
    "1. Place the best attribute of the dataset at the root of the tree.\n",
    "2. Split the training set into subsets. Subsets should be made in such a way that each subset contains data with the same value for an attribute.\n",
    "3. Repeat step 1 and step 2 on each subset until you find leaf nodes in all the branches of the tree.\n",
    "\n",
    "### ***Assumptions while creating Decision Tree***\n",
    "\n",
    "* At the beginning, the whole training set is considered as the root.\n",
    "* Feature values are preferred to be categorical. If the values are continuous then they are discretized prior to building the model.\n",
    "* Records are distributed recursively on the basis of attribute values.\n",
    "* Order to placing attributes as root or internal node of the tree is done by using some statistical approach.\n",
    "\n",
    "## Principal Component Analysis\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48d3ba6fd8913976b5b8240356e2a25bc7de293def346b194c53738ff49bc619"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
